{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from decision_tree_tool import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaboostModel():\n",
    "    def __init__(self, model_type='classification'):   #변수 초기화\n",
    "        model_types = ['classification', 'regression']\n",
    "        assert model_type in model_types, f'model_type must be the one of the {model_types}' #조건이 True임을 보증\n",
    "        self.model_type = model_type       #문제 타입\n",
    "        self.fitting_models = None        #개별 모형 리스트\n",
    "        self.coef_list = None             #가중치 알파\n",
    "        self.weight_lists = None          #업데이트된 가중치\n",
    "        self.selected_idx_lists = None    #샘플링된 인덱스\n",
    "        self.error_lists = None           #오분류 관측치\n",
    "        self.estimator_predicts = None    #개별 모형의 예측결과\n",
    "        self.uniq_labels = None           #클래스 라벨\n",
    "        self.num_class = None             #클래수 개수\n",
    "        self.num_data = None              #데이터 개수\n",
    "        self.loss = None                  #회귀문제에서의 로스 타임\n",
    "        \n",
    "    def get_loss(self, y1, y2, sample_weights, loss):  #Weight Loss Functhion\n",
    "        D = np.max(np.abs(y1-y2))\n",
    "        if loss == 'linear':\n",
    "            L_array = np.abs(y1-y2)/D\n",
    "        elif loss == 'square':\n",
    "            L_array = np.square(y1-y2)/(D**2)\n",
    "        else:\n",
    "            L_array = 1 - np.exp(-np.abs(y1-y2)/D)\n",
    "            \n",
    "        L_bar = np.dot(L_array, sample_weights)\n",
    "        return L_bar, L_array\n",
    "    \n",
    "    def get_weighted_median(self, x, weights):       #가중 중앙값 계산\n",
    "        sum_val = 0.5 * np.sum(weights)\n",
    "        cum_sum = weights[0]\n",
    "        i = 0\n",
    "        while cum_sum < sum_val:\n",
    "            i += 1\n",
    "            cum_sum += weights[i]\n",
    "        return x[i]\n",
    "    \n",
    "    #Adaboost 알고리즘\n",
    "    def fit(self, X, y, type_of_col, n_estimators=10, random_state=100, loss='linear'):\n",
    "        self.uniq_labels = np.unique(y)   #클래스 라벨은 y의 고윳값들\n",
    "        \n",
    "        #초기화\n",
    "        fitting_models = []\n",
    "        coef_list = []            #가중치 알파\n",
    "        weight_lists = []         #업데이트된 가중치\n",
    "        selected_idx_lists = []   #샘플링된 인덱스\n",
    "        error_lists = []          #오분류 관측치\n",
    "        estimator_predicts = []     #별 모형의 예측결과\n",
    "        n = X.shape[0]            #관측치 개수\n",
    "        self.num_data = n         #데이터 개수\n",
    "        w = np.array([1/n] * len(y))\n",
    "        col_name = X.columns\n",
    "        epsilon = 1e-10\n",
    "        random.seed(random_state)\n",
    "        \n",
    "        if self.model_type == 'classification':  #모델 타입이 분류이면\n",
    "            K = len(self.uniq_labels)\n",
    "            self.num_class = K           #클래수 개수는 클래스 라벨의 길이\n",
    "            \n",
    "            for ne in range(n_estimators):       #초기 가중치 W\n",
    "                clf = DecisionTree(tree_type = self.model_type)\n",
    "                clf.fit(X , y, max_depth = 2, type_of_col = type_of_col, auto_determine_type_of_col = False)\n",
    "                \n",
    "                #개별 모형의 예측값과 오류 계산\n",
    "                y_predict = np.array(clf.predict(X))         #개별 모형의 예측값\n",
    "                incorrect = y != y_predict\n",
    "                error = np.sum(w[incorrect]) / np.sum(w)     #오류율\n",
    "                \n",
    "                if error == 0:\n",
    "                    break\n",
    "                    \n",
    "                estimator_predicts.append(y_predict)\n",
    "                error_lists.append(error)\n",
    "                alpha = np.log((1-error) / (error + epsilon)) + np.log(K-1)   #알파값, classifier의 가중치\n",
    "                fitting_models.append(clf)\n",
    "                coef_list.append(alpha)\n",
    "                \n",
    "                if ne == n_estimators - 1:\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    #가중치 업데이트 및 새로운 학습데이터 복원 추출\n",
    "                    new_weight = w.copy()\n",
    "                    new_weight = new_weight * np.exp(alpha * incorrect)\n",
    "                    new_weight = new_weight / np.sum(new_weight)\n",
    "                    weight_lists.append(new_weight)\n",
    "                    sampling_idx = random.choices(range(n), weights = new_weight, k = n)\n",
    "                    selected_idx_lists.append(sampling_idx)\n",
    "                    \n",
    "                    X = X.iloc[sampling_idx, :].reset_index(drop=True)\n",
    "                    y = y[sampling_idx]\n",
    "                    w = np.array([1/n]*len(y))\n",
    "                    \n",
    "                    \n",
    "        self.fitting_models = fitting_models\n",
    "        self.coef_list = np.array(coef_list)\n",
    "        self.weight_lists = weight_lists\n",
    "        self.selected_idx_lists = selected_idx_lists\n",
    "        self.error_lists = np.array(error_lists)\n",
    "        self.estimator_predicts = estimator_predicts\n",
    "        \n",
    "    def predict(self, X):      #예측수행함수\n",
    "        n = self.num_data      #관측치 개수\n",
    "        pred = []\n",
    "        temp_pred_list = [model.predict(X) for model in self.fitting_models]\n",
    "        temp_pred_tuple = tuple(zip(*temp_pred_list))\n",
    "        \n",
    "        if self.model_type == 'classification':\n",
    "            alpha_list = self.coef_list\n",
    "            K = self.num_class\n",
    "            \n",
    "            for i in range(n):\n",
    "                temp_labels = [0]*K\n",
    "                temp_pred = np.array(temp_pred_tuple[i])\n",
    "                for k in range(K):\n",
    "                    temp_labels[k] = np.sum(alpha_list[temp_pred == K])\n",
    "                pred.append(np.argmax(temp_labels))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런 붓꽃 데이터에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['species'] = [iris.target_names[x] for x in iris.target]\n",
    "\n",
    "species_to_labels = dict(zip(df['species'].unique(), range(len(df['species'].unique()))))\n",
    "df['label'] = df['species'].map(species_to_labels)\n",
    "\n",
    "#M = 10으로 모형 적합\n",
    "X, y = df.iloc[:,:4], df['label'].values\n",
    "clf = AdaboostModel(model_type = 'classification')\n",
    "clf.fit(X, y, type_of_col = ['continuous'] * 4, n_estimators = 10)\n",
    "np.mean(y == clf.predict(X)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
