{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST DATA 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "data_list = data_file.readlines() #파일의 모든 행을 읽기\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data 시각화 : 구분자로 쉼표를 이용해 긴 텍스트 문자열을 개별 값으로 분리\n",
    "레이블 값인 첫 번째 값은 무시하고 나머지 28*28=784의 값을 추출한 후, 이를 28*28 행렬로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7534910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "all_values = data_list[0].split(',')\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28)) #문자열을 실수로 변환한 후 배열(28*28) 생성\n",
    "plt.imshow(image_array, cmap='Blues', interpolation='None') #행렬 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 학습 데이터 준비하기 : 데이터 값의 범위 재조정 -> 활성화 함수의 수용 범위 안에 데이터가 있어야\n",
    "신경망의 효율 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.02164706, 0.07988235, 0.07988235,\n",
       "       0.07988235, 0.49917647, 0.538     , 0.68941176, 0.11094118,\n",
       "       0.65447059, 1.        , 0.96894118, 0.50305882, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.12647059, 0.14976471, 0.37494118, 0.60788235,\n",
       "       0.67      , 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.88352941, 0.67776471, 0.99223529, 0.94952941,\n",
       "       0.76705882, 0.25847059, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.20023529, 0.934     ,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.98447059, 0.37105882,\n",
       "       0.32835294, 0.32835294, 0.22741176, 0.16141176, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.07988235, 0.86023529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.77870588, 0.71658824,\n",
       "       0.96894118, 0.94564706, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.32058824, 0.61564706, 0.42541176, 0.99223529, 0.99223529,\n",
       "       0.80588235, 0.05270588, 0.01      , 0.17694118, 0.60788235,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.06435294,\n",
       "       0.01388235, 0.60788235, 0.99223529, 0.35941176, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.54964706,\n",
       "       0.99223529, 0.74764706, 0.01776471, 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.05270588, 0.74764706, 0.99223529,\n",
       "       0.28176471, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.14588235, 0.94564706, 0.88352941, 0.63117647,\n",
       "       0.42929412, 0.01388235, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.32447059, 0.94176471, 0.99223529, 0.99223529, 0.472     ,\n",
       "       0.10705882, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.18470588,\n",
       "       0.73211765, 0.99223529, 0.99223529, 0.59235294, 0.11482353,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.07211765, 0.37105882,\n",
       "       0.98835294, 0.99223529, 0.736     , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.97670588, 0.99223529,\n",
       "       0.97670588, 0.25847059, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.18858824, 0.51470588,\n",
       "       0.72047059, 0.99223529, 0.99223529, 0.81364706, 0.01776471,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.16141176,\n",
       "       0.58458824, 0.89905882, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.98058824, 0.71658824, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.10317647, 0.45258824, 0.868     , 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.79035294, 0.31282353, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.09929412, 0.26623529, 0.83694118, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.77870588, 0.32447059,\n",
       "       0.01776471, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.07988235, 0.67388235, 0.86023529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.99223529, 0.76705882,\n",
       "       0.32058824, 0.04494118, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.22352941, 0.67776471,\n",
       "       0.88741176, 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.95729412, 0.52635294, 0.05270588, 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.538     , 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.83305882, 0.53411765, 0.52247059, 0.07211765, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0~255 사이의 입력 색상 값들의 범위를 0.01~1.0 사이에 속하도록 조정\n",
    "scaled_input = (np.asfarray(all_values[1:]) / 255.0*0.99) + 0.01\n",
    "scaled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onodes = 10\n",
    "targets = np.zeros(onodes) + 0.01\n",
    "targets[int(all_values[0])] = 0.99\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "class neuralNetwork():\n",
    "    #신경망 초기화\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #가중치\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, - 0.5),(self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        #activation function\n",
    "        self.activation_function = lambda x : scipy.special.expit(x) #expit함수는 sigmoid 함수\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    #신경망 학습\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs  #출력층의 오차 계산\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)  #은닉층의 역전파된 오차 계산\n",
    "        self.who += self.lr*np.dot((output_errors*final_outputs*(1.0-final_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    #신경망 질의\n",
    "    def query(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T #입력리스트를 2차원행렬로 변환\n",
    "        hidden_inputs = np.dot(self.wih, inputs) #은닉층으로 들어오는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)  #은닉층에서 나가는 신호 계산\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)  #출력층으로 들어오는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)   #출력층에서 나가는 신호 계산\n",
    "        return final_outputs\n",
    "    \n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "learning_rate = 0.2\n",
    "\n",
    "N = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100개의 레코드를 가진 toy data를 불러와서 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "data_list = data_file.readlines() #파일의 모든 행을 읽기\n",
    "data_file.close()\n",
    "\n",
    "for record in data_list:\n",
    "    all_values = record.split(',')\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    targets = np.zeros(output_nodes) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    N.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.53639959e-02],\n",
       "       [1.91360876e-03],\n",
       "       [1.00235176e-02],\n",
       "       [8.76596434e-03],\n",
       "       [7.65933476e-03],\n",
       "       [2.73923181e-02],\n",
       "       [3.57975761e-04],\n",
       "       [9.85310810e-01],\n",
       "       [3.57288821e-02],\n",
       "       [7.68256899e-03]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_file = open(\"mnist_test_10.csv\", 'r', encoding='utf8')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "all_values = test_data_list[0].split(',')\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "plt.imshow(image_array, cmap = 'Blues', interpolation = 'None')\n",
    "\n",
    "N.query((np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터를 이용해 학습 및 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file = open(\"mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "test_data_file = open(\"mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.623\n"
     ]
    }
   ],
   "source": [
    "scorecard = []   #신경망의 성능 지표가 되는 성적표 초기화\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0])\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    outputs = N.query(inputs)\n",
    "    label = np.argmax(outputs)  #행렬 내 가장 큰 값을 찾아 위치를 알려줌\n",
    "    if (label == correct_label):\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate, 주기, 은닉 노드 수 변경을 통한 신경망 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.601\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "learning_rate = 0.5\n",
    "\n",
    "M = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "epochs = 7  #주기 : 학습데이터가 학습을 위해 이용되는 횟수\n",
    "\n",
    "for e in range(epochs):\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        M.train(inputs, targets)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
